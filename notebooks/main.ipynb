{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the working directory\n",
    "import os\n",
    "os.chdir('/Users/vishalraj/GitHub/Flight_Fare_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import load_and_save_data_by_folder\n",
    "\n",
    "path = 'data/raw'\n",
    "\n",
    "# Load and save concatenated data by folder\n",
    "load_and_save_data_by_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              legId  searchDate  flightDate startingAirport  \\\n",
      "0  ee4aaff43c557e1704ebf52b8abf25ad  2022-05-13  2022-06-15             ATL   \n",
      "1  284bffb121ffdafba55f69d6d89a4b7d  2022-05-13  2022-06-15             ATL   \n",
      "2  8efdd07b82644146d45978f61d081f3b  2022-05-13  2022-06-15             ATL   \n",
      "3  e03c8964b4feb4e206636a9c5c0015b2  2022-05-13  2022-06-15             ATL   \n",
      "4  f44658d6761962cecc3eabc0a29d6ef9  2022-05-13  2022-06-15             ATL   \n",
      "\n",
      "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
      "0                BOS        PT8H51M           False         False      False   \n",
      "1                BOS       PT12H31M           False         False      False   \n",
      "2                BOS        PT4H35M           False         False      False   \n",
      "3                BOS        PT4H38M           False         False      False   \n",
      "4                BOS        PT6H43M           False         False      False   \n",
      "\n",
      "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
      "0     124.78  ...           1655327040||1655351760   \n",
      "1     138.58  ...           1655309340||1655349060   \n",
      "2     148.60  ...           1655312340||1655321940   \n",
      "3     148.60  ...           1655300100||1655309340   \n",
      "4     148.60  ...           1655304660||1655321940   \n",
      "\n",
      "                              segmentsArrivalTimeRaw  \\\n",
      "0  2022-06-15T17:04:00.000-04:00||2022-06-15T23:5...   \n",
      "1  2022-06-15T12:09:00.000-04:00||2022-06-15T23:1...   \n",
      "2  2022-06-15T12:59:00.000-04:00||2022-06-15T15:3...   \n",
      "3  2022-06-15T09:35:00.000-04:00||2022-06-15T12:0...   \n",
      "4  2022-06-15T10:51:00.000-04:00||2022-06-15T15:3...   \n",
      "\n",
      "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
      "0                   FLL||BOS                     ATL||FLL   \n",
      "1                   MCO||BOS                     ATL||MCO   \n",
      "2                   DCA||BOS                     ATL||DCA   \n",
      "3                   PHL||BOS                     ATL||PHL   \n",
      "4                   DCA||BOS                     ATL||DCA   \n",
      "\n",
      "                    segmentsAirlineName segmentsAirlineCode  \\\n",
      "0      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "2  American Airlines||American Airlines              AA||AA   \n",
      "3  American Airlines||American Airlines              AA||AA   \n",
      "4  American Airlines||American Airlines              AA||AA   \n",
      "\n",
      "                        segmentsEquipmentDescription  \\\n",
      "0                                                 ||   \n",
      "1  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
      "2                           Embraer 175||Airbus A319   \n",
      "3                           Airbus A320||Airbus A321   \n",
      "4             Canadair Regional Jet 900||Airbus A319   \n",
      "\n",
      "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \n",
      "0               7140||11760       None||None      coach||coach  \n",
      "1               5340||11160       None||None      coach||coach  \n",
      "2                6900||5940         541||406      coach||coach  \n",
      "3                7440||5160         667||280      coach||coach  \n",
      "4                6900||5940         541||406      coach||coach  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/interim/ATL/ATL_concatenated.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legId': dtype('O'), 'searchDate': dtype('O'), 'flightDate': dtype('O'), 'startingAirport': dtype('O'), 'destinationAirport': dtype('O'), 'travelDuration': dtype('O'), 'isBasicEconomy': dtype('bool'), 'isRefundable': dtype('bool'), 'isNonStop': dtype('bool'), 'totalFare': dtype('float64'), 'totalTravelDistance': dtype('float64'), 'segmentsDepartureTimeEpochSeconds': dtype('O'), 'segmentsDepartureTimeRaw': dtype('O'), 'segmentsArrivalTimeEpochSeconds': dtype('O'), 'segmentsArrivalTimeRaw': dtype('O'), 'segmentsArrivalAirportCode': dtype('O'), 'segmentsDepartureAirportCode': dtype('O'), 'segmentsAirlineName': dtype('O'), 'segmentsAirlineCode': dtype('O'), 'segmentsEquipmentDescription': dtype('O'), 'segmentsDurationInSeconds': dtype('O'), 'segmentsDistance': dtype('O'), 'segmentsCabinCode': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# Extract dtypes\n",
    "dtype_dict = df.dtypes.to_dict()\n",
    "\n",
    "print(dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the global encoder.\n",
      "Transforming the data using global encoder.\n",
      "Fitting the global encoder.\n",
      "Transforming the data using global encoder.\n",
      "Fitting the global encoder.\n",
      "Transforming the data using global encoder.\n",
      "Fitting the global encoder.\n",
      "Transforming the data using global encoder.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The output of the 'cat_emb' transformer should be 2D (scipy matrix, array, or pandas DataFrame).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m DataPreprocessor()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Process all folders\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m preprocessor\u001b[39m.\u001b[39;49mprocess_all_folders()\n",
      "File \u001b[0;32m~/GitHub/Flight_Fare_Prediction/src/data/data_preprocessor.py:270\u001b[0m, in \u001b[0;36mDataPreprocessor.process_all_folders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mdata/interim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/interim/\u001b[39m\u001b[39m{\u001b[39;00mfolder\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 270\u001b[0m         processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_folder(folder)\n\u001b[1;32m    271\u001b[0m         \u001b[39mif\u001b[39;00m processed:  \u001b[39m# Only update if process_folder was successful\u001b[39;00m\n\u001b[1;32m    272\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_category_mappings()\n",
      "File \u001b[0;32m~/GitHub/Flight_Fare_Prediction/src/data/data_preprocessor.py:259\u001b[0m, in \u001b[0;36mDataPreprocessor.process_folder\u001b[0;34m(self, folder)\u001b[0m\n\u001b[1;32m    256\u001b[0m concatenated_data_list \u001b[39m=\u001b[39m [chunk \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks]\n\u001b[1;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(concatenated_data_list, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 259\u001b[0m processed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess_data()\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/processed/\u001b[39m\u001b[39m{\u001b[39;00mfolder\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[1;32m    261\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/processed/\u001b[39m\u001b[39m{\u001b[39;00mfolder\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/Flight_Fare_Prediction/src/data/data_preprocessor.py:150\u001b[0m, in \u001b[0;36mDataPreprocessor.preprocess_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Check if the preprocessor is already instantiated\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor \u001b[39m=\u001b[39m ColumnTransformer(\n\u001b[1;32m    144\u001b[0m         transformers\u001b[39m=\u001b[39m[\n\u001b[1;32m    145\u001b[0m             (\u001b[39m'\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m'\u001b[39m, numerical_transformer, numerical_features),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m         ]\n\u001b[1;32m    149\u001b[0m     )\n\u001b[0;32m--> 150\u001b[0m     transformed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessor\u001b[39m.\u001b[39;49mfit_transform(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     transformed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/compose/_column_transformer.py:764\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output_ \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers(transformers)\n\u001b[0;32m--> 764\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_output(Xs)\n\u001b[1;32m    765\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record_output_indices(Xs)\n\u001b[1;32m    767\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hstack(\u001b[39mlist\u001b[39m(Xs))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/compose/_column_transformer.py:624\u001b[0m, in \u001b[0;36mColumnTransformer._validate_output\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mfor\u001b[39;00m Xs, name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, names):\n\u001b[1;32m    623\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(Xs, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    625\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe output of the \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m transformer should be 2D (scipy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmatrix, array, or pandas DataFrame).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name)\n\u001b[1;32m    627\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The output of the 'cat_emb' transformer should be 2D (scipy matrix, array, or pandas DataFrame)."
     ]
    }
   ],
   "source": [
    "from src.data.data_preprocessor import DataPreprocessor\n",
    "\n",
    "# Create an instance of the DataPreprocessor class\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Process all folders\n",
    "preprocessor.process_all_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "295750/295750 [==============================] - 352s 1ms/step - loss: 25743.1738 - mae: 113.1718 - mse: 25743.1738 - val_loss: 23917.2227 - val_mae: 109.3110 - val_mse: 23917.2227 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "   146/295750 [..............................] - ETA: 5:07 - loss: 24212.4219 - mae: 110.3315 - mse: 24212.4219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalraj/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295750/295750 [==============================] - 312s 1ms/step - loss: 23921.5488 - mae: 108.3392 - mse: 23921.5488 - val_loss: 23174.2969 - val_mae: 105.3933 - val_mse: 23174.2969 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "295750/295750 [==============================] - 305s 1ms/step - loss: 23546.7129 - mae: 107.1621 - mse: 23546.7129 - val_loss: 22977.2051 - val_mae: 105.0599 - val_mse: 22977.2051 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "295750/295750 [==============================] - 296s 999us/step - loss: 23348.7617 - mae: 106.5543 - mse: 23348.7617 - val_loss: 22696.9160 - val_mae: 104.4312 - val_mse: 22696.9160 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "295750/295750 [==============================] - 310s 1ms/step - loss: 23214.1211 - mae: 106.1353 - mse: 23214.1211 - val_loss: 22622.3184 - val_mae: 103.3761 - val_mse: 22622.3184 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "295750/295750 [==============================] - 307s 1ms/step - loss: 23119.4062 - mae: 105.8459 - mse: 23119.4062 - val_loss: 22535.2969 - val_mae: 103.9269 - val_mse: 22535.2969 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "295750/295750 [==============================] - 1197s 4ms/step - loss: 23037.9883 - mae: 105.6008 - mse: 23037.9883 - val_loss: 22519.7520 - val_mae: 103.4555 - val_mse: 22519.7520 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "295750/295750 [==============================] - 302s 1ms/step - loss: 22979.9980 - mae: 105.4073 - mse: 22979.9980 - val_loss: 22344.1074 - val_mae: 103.7559 - val_mse: 22344.1074 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "295750/295750 [==============================] - 1288s 4ms/step - loss: 22927.6055 - mae: 105.2665 - mse: 22927.6055 - val_loss: 22296.0684 - val_mae: 103.1470 - val_mse: 22296.0684 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "295750/295750 [==============================] - 1196s 4ms/step - loss: 22881.8340 - mae: 105.1250 - mse: 22881.8340 - val_loss: 22504.4512 - val_mae: 104.8010 - val_mse: 22504.4512 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "295750/295750 [==============================] - 307s 1ms/step - loss: 22840.3887 - mae: 104.9997 - mse: 22840.3887 - val_loss: 22140.4902 - val_mae: 102.9345 - val_mse: 22140.4902 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "295750/295750 [==============================] - 569s 2ms/step - loss: 22783.8926 - mae: 104.8456 - mse: 22783.8926 - val_loss: 22185.3711 - val_mae: 102.8626 - val_mse: 22185.3711 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "295750/295750 [==============================] - 527s 2ms/step - loss: 22744.1582 - mae: 104.7428 - mse: 22744.1582 - val_loss: 22060.0469 - val_mae: 103.2853 - val_mse: 22060.0469 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "295750/295750 [==============================] - 1423s 5ms/step - loss: 22710.7012 - mae: 104.6482 - mse: 22710.7012 - val_loss: 22114.2969 - val_mae: 103.5656 - val_mse: 22114.2969 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "295750/295750 [==============================] - 298s 1ms/step - loss: 22680.5801 - mae: 104.5665 - mse: 22680.5801 - val_loss: 21947.1641 - val_mae: 102.2188 - val_mse: 21947.1641 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "295750/295750 [==============================] - 600s 2ms/step - loss: 22651.3359 - mae: 104.4950 - mse: 22651.3359 - val_loss: 21988.1055 - val_mae: 102.1874 - val_mse: 21988.1055 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "295750/295750 [==============================] - 550s 2ms/step - loss: 22630.8457 - mae: 104.4233 - mse: 22630.8457 - val_loss: 21890.0176 - val_mae: 101.7823 - val_mse: 21890.0176 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "295750/295750 [==============================] - 570s 2ms/step - loss: 22608.3711 - mae: 104.3622 - mse: 22608.3711 - val_loss: 22032.4980 - val_mae: 101.9089 - val_mse: 22032.4980 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "295750/295750 [==============================] - 573s 2ms/step - loss: 22596.9414 - mae: 104.3388 - mse: 22596.9414 - val_loss: 21920.6602 - val_mae: 102.4510 - val_mse: 21920.6602 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "295750/295750 [==============================] - 1451s 5ms/step - loss: 22573.0820 - mae: 104.2599 - mse: 22573.0820 - val_loss: 21928.9746 - val_mae: 103.1202 - val_mse: 21928.9746 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "295750/295750 [==============================] - 1206s 4ms/step - loss: 22552.2949 - mae: 104.1901 - mse: 22552.2949 - val_loss: 21850.7148 - val_mae: 101.1628 - val_mse: 21850.7148 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "295750/295750 [==============================] - 563s 2ms/step - loss: 22537.9043 - mae: 104.1428 - mse: 22537.9043 - val_loss: 21831.7090 - val_mae: 102.0556 - val_mse: 21831.7090 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "295750/295750 [==============================] - 3644s 12ms/step - loss: 22524.5586 - mae: 104.1042 - mse: 22524.5586 - val_loss: 21918.9805 - val_mae: 102.1123 - val_mse: 21918.9805 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "295750/295750 [==============================] - 2079s 7ms/step - loss: 22515.0137 - mae: 104.0559 - mse: 22515.0137 - val_loss: 21806.4434 - val_mae: 101.4293 - val_mse: 21806.4434 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "295750/295750 [==============================] - 1180s 4ms/step - loss: 22499.4199 - mae: 104.0059 - mse: 22499.4199 - val_loss: 21794.2344 - val_mae: 101.7104 - val_mse: 21794.2344 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "295750/295750 [==============================] - 277s 937us/step - loss: 22483.4297 - mae: 103.9808 - mse: 22483.4297 - val_loss: 21802.0762 - val_mae: 102.3859 - val_mse: 21802.0762 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "295750/295750 [==============================] - 539s 2ms/step - loss: 22479.9082 - mae: 103.9519 - mse: 22479.9082 - val_loss: 21743.7168 - val_mae: 101.4413 - val_mse: 21743.7168 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "295750/295750 [==============================] - 535s 2ms/step - loss: 22469.0430 - mae: 103.9294 - mse: 22469.0430 - val_loss: 21897.7402 - val_mae: 103.4573 - val_mse: 21897.7402 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "295750/295750 [==============================] - 2255s 8ms/step - loss: 22452.9102 - mae: 103.8682 - mse: 22452.9102 - val_loss: 21963.9180 - val_mae: 103.8900 - val_mse: 21963.9180 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "295750/295750 [==============================] - 2068s 7ms/step - loss: 22444.2793 - mae: 103.8401 - mse: 22444.2793 - val_loss: 21770.2832 - val_mae: 102.3272 - val_mse: 21770.2832 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "295750/295750 [==============================] - 1167s 4ms/step - loss: 22437.2695 - mae: 103.8105 - mse: 22437.2695 - val_loss: 21762.3711 - val_mae: 101.6226 - val_mse: 21762.3711 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "295750/295750 [==============================] - 1171s 4ms/step - loss: 22422.1758 - mae: 103.7671 - mse: 22422.1758 - val_loss: 21669.4844 - val_mae: 101.3744 - val_mse: 21669.4844 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "295750/295750 [==============================] - 281s 949us/step - loss: 22425.4941 - mae: 103.7631 - mse: 22425.4941 - val_loss: 21800.6152 - val_mae: 102.5614 - val_mse: 21800.6152 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "174279/295750 [================>.............] - ETA: 1:46 - loss: 22377.6152 - mae: 103.6817 - mse: 22377.6152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39msaved_model/best_model.h5\u001b[39m\u001b[39m\"\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([train_wide, train_deep], train_labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m([valid_wide, valid_deep], valid_labels),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stop, reduce_lr, model_checkpoint])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Save the final model to disk\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodels/my_final_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.train_model import load_and_combine_data, build_model\n",
    "\n",
    "# Load and preprocess data\n",
    "data = load_and_combine_data()\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = build_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "# Split data into wide and deep components for training and validation\n",
    "# Convert boolean columns to int\n",
    "train_data['flightDate_is_weekend'] = train_data['flightDate_is_weekend'].astype(int)\n",
    "valid_data['flightDate_is_weekend'] = valid_data['flightDate_is_weekend'].astype(int)\n",
    "test_data['flightDate_is_weekend'] = test_data['flightDate_is_weekend'].astype(int)\n",
    "\n",
    "# Split data into wide and deep components, and ensure they are of type float32\n",
    "train_wide = train_data[['startingAirport', 'destinationAirport', 'segmentsCabinCode', 'flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']].values.astype('float32')\n",
    "train_deep = train_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']].values.astype('float32')\n",
    "train_labels = train_data['totalFare'].values.astype('float32')\n",
    "\n",
    "valid_wide = valid_data[['startingAirport', 'destinationAirport', 'segmentsCabinCode', 'flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']].values.astype('float32')\n",
    "valid_deep = valid_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']].values.astype('float32')\n",
    "valid_labels = valid_data['totalFare'].values.astype('float32')\n",
    "\n",
    "# Train the model with early stopping, reduce learning rate on plateau, and model checkpoint\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"saved_model/best_model.keras\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit([train_wide, train_deep], train_labels, \n",
    "                    validation_data=([valid_wide, valid_deep], valid_labels),\n",
    "                    epochs=100, \n",
    "                    callbacks=[early_stop, reduce_lr, model_checkpoint])\n",
    "\n",
    "# Save the final model to disk\n",
    "model.save(\"models/my_final_model.keras\")\n",
    "\n",
    "# Model Evaluation\n",
    "test_wide = test_data[['startingAirport', 'destinationAirport', 'segmentsCabinCode', 'flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']]\n",
    "test_deep = test_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']]\n",
    "test_labels = test_data['totalFare']\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = model.predict([test_wide, test_deep])\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "rmse.update_state(test_labels, predictions)\n",
    "mae.update_state(test_labels, predictions)\n",
    "\n",
    "print(f\"RMSE on test set: {rmse.result().numpy()}\")\n",
    "print(f\"MAE on test set: {mae.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot MAE and MSE\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.legend()\n",
    "plt.title('Mean Absolute Error Progression During Training')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mse'], label='Train MSE')\n",
    "plt.plot(history.history['val_mse'], label='Validation MSE')\n",
    "plt.legend()\n",
    "plt.title('Mean Squared Error Progression During Training')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
