{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"urllib3\")\n",
    "# Setting the working directory\n",
    "import os\n",
    "os.chdir('/Users/vishalraj/GitHub/Flight_Fare_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import load_and_save_data_by_folder\n",
    "\n",
    "path = 'data/raw'\n",
    "\n",
    "# Load and save concatenated data by folder\n",
    "load_and_save_data_by_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              legId  searchDate  flightDate startingAirport  \\\n",
      "0  ee4aaff43c557e1704ebf52b8abf25ad  2022-05-13  2022-06-15             ATL   \n",
      "1  284bffb121ffdafba55f69d6d89a4b7d  2022-05-13  2022-06-15             ATL   \n",
      "2  8efdd07b82644146d45978f61d081f3b  2022-05-13  2022-06-15             ATL   \n",
      "3  e03c8964b4feb4e206636a9c5c0015b2  2022-05-13  2022-06-15             ATL   \n",
      "4  f44658d6761962cecc3eabc0a29d6ef9  2022-05-13  2022-06-15             ATL   \n",
      "\n",
      "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
      "0                BOS        PT8H51M           False         False      False   \n",
      "1                BOS       PT12H31M           False         False      False   \n",
      "2                BOS        PT4H35M           False         False      False   \n",
      "3                BOS        PT4H38M           False         False      False   \n",
      "4                BOS        PT6H43M           False         False      False   \n",
      "\n",
      "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
      "0     124.78  ...           1655327040||1655351760   \n",
      "1     138.58  ...           1655309340||1655349060   \n",
      "2     148.60  ...           1655312340||1655321940   \n",
      "3     148.60  ...           1655300100||1655309340   \n",
      "4     148.60  ...           1655304660||1655321940   \n",
      "\n",
      "                              segmentsArrivalTimeRaw  \\\n",
      "0  2022-06-15T17:04:00.000-04:00||2022-06-15T23:5...   \n",
      "1  2022-06-15T12:09:00.000-04:00||2022-06-15T23:1...   \n",
      "2  2022-06-15T12:59:00.000-04:00||2022-06-15T15:3...   \n",
      "3  2022-06-15T09:35:00.000-04:00||2022-06-15T12:0...   \n",
      "4  2022-06-15T10:51:00.000-04:00||2022-06-15T15:3...   \n",
      "\n",
      "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
      "0                   FLL||BOS                     ATL||FLL   \n",
      "1                   MCO||BOS                     ATL||MCO   \n",
      "2                   DCA||BOS                     ATL||DCA   \n",
      "3                   PHL||BOS                     ATL||PHL   \n",
      "4                   DCA||BOS                     ATL||DCA   \n",
      "\n",
      "                    segmentsAirlineName segmentsAirlineCode  \\\n",
      "0      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "2  American Airlines||American Airlines              AA||AA   \n",
      "3  American Airlines||American Airlines              AA||AA   \n",
      "4  American Airlines||American Airlines              AA||AA   \n",
      "\n",
      "                        segmentsEquipmentDescription  \\\n",
      "0                                                 ||   \n",
      "1  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
      "2                           Embraer 175||Airbus A319   \n",
      "3                           Airbus A320||Airbus A321   \n",
      "4             Canadair Regional Jet 900||Airbus A319   \n",
      "\n",
      "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \n",
      "0               7140||11760       None||None      coach||coach  \n",
      "1               5340||11160       None||None      coach||coach  \n",
      "2                6900||5940         541||406      coach||coach  \n",
      "3                7440||5160         667||280      coach||coach  \n",
      "4                6900||5940         541||406      coach||coach  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/interim/ATL/ATL_concatenated.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legId': dtype('O'), 'searchDate': dtype('O'), 'flightDate': dtype('O'), 'startingAirport': dtype('O'), 'destinationAirport': dtype('O'), 'travelDuration': dtype('O'), 'isBasicEconomy': dtype('bool'), 'isRefundable': dtype('bool'), 'isNonStop': dtype('bool'), 'totalFare': dtype('float64'), 'totalTravelDistance': dtype('float64'), 'segmentsDepartureTimeEpochSeconds': dtype('O'), 'segmentsDepartureTimeRaw': dtype('O'), 'segmentsArrivalTimeEpochSeconds': dtype('O'), 'segmentsArrivalTimeRaw': dtype('O'), 'segmentsArrivalAirportCode': dtype('O'), 'segmentsDepartureAirportCode': dtype('O'), 'segmentsAirlineName': dtype('O'), 'segmentsAirlineCode': dtype('O'), 'segmentsEquipmentDescription': dtype('O'), 'segmentsDurationInSeconds': dtype('O'), 'segmentsDistance': dtype('O'), 'segmentsCabinCode': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# Extract dtypes\n",
    "dtype_dict = df.dtypes.to_dict()\n",
    "\n",
    "print(dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before explosion:\n",
      "                              legId  searchDate  flightDate startingAirport  \\\n",
      "0  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "1  d813ebd107e3fa700206c0d96015da7a  2022-04-19  2022-05-20             OAK   \n",
      "2  e8ece5ad6f5962c696e06e031fc2a24a  2022-04-19  2022-05-20             OAK   \n",
      "3  c004a54681335100f326c9613b3c9448  2022-04-19  2022-05-20             OAK   \n",
      "4  4a42bbf77211b4afa7b9e14005949120  2022-04-19  2022-05-20             OAK   \n",
      "\n",
      "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
      "0                ATL        PT7H52M           False         False      False   \n",
      "1                ATL        PT6H15M           False         False      False   \n",
      "2                ATL         PT9H6M           False         False      False   \n",
      "3                ATL        PT6H17M           False         False      False   \n",
      "4                ATL       PT14H12M           False         False      False   \n",
      "\n",
      "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
      "0     103.98  ...           1653107460||1653126600   \n",
      "1     216.58  ...           1653067080||1653084660   \n",
      "2     216.58  ...           1653056820||1653084660   \n",
      "3     237.58  ...           1653110940||1653127980   \n",
      "4     307.21  ...           1653115560||1653159180   \n",
      "\n",
      "                              segmentsArrivalTimeRaw  \\\n",
      "0  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "1  2022-05-20T10:18:00.000-07:00||2022-05-20T18:1...   \n",
      "2  2022-05-20T07:27:00.000-07:00||2022-05-20T18:1...   \n",
      "3  2022-05-20T22:29:00.000-07:00||2022-05-21T06:1...   \n",
      "4  2022-05-20T23:46:00.000-07:00||2022-05-21T14:5...   \n",
      "\n",
      "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
      "0                   DEN||ATL                     OAK||DEN   \n",
      "1                   LAX||ATL                     OAK||LAX   \n",
      "2                   LAX||ATL                     OAK||LAX   \n",
      "3                   LAS||ATL                     OAK||LAS   \n",
      "4                   SEA||ATL                     OAK||SEA   \n",
      "\n",
      "                    segmentsAirlineName segmentsAirlineCode  \\\n",
      "0  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "2      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "3      Spirit Airlines||Spirit Airlines              NK||NK   \n",
      "4      Alaska Airlines||Alaska Airlines              AS||AS   \n",
      "\n",
      "                        segmentsEquipmentDescription  \\\n",
      "0                                      ||Airbus A320   \n",
      "1                  ||AIRBUS INDUSTRIE A320 SHARKLETS   \n",
      "2  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
      "3       AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319   \n",
      "4                     Boeing 737-900||Boeing 737-900   \n",
      "\n",
      "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \n",
      "0               9180||10620        943||1207      coach||coach  \n",
      "1               4920||15600       None||None      coach||coach  \n",
      "2               4920||15600       None||None      coach||coach  \n",
      "3               5580||13980       None||None      coach||coach  \n",
      "4               7500||17580        672||2178      coach||coach  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Data after explosion:\n",
      "                              legId  searchDate  flightDate startingAirport  \\\n",
      "0  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "1  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "2  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "3  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "4  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
      "\n",
      "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
      "0                ATL        PT7H52M           False         False      False   \n",
      "1                ATL        PT7H52M           False         False      False   \n",
      "2                ATL        PT7H52M           False         False      False   \n",
      "3                ATL        PT7H52M           False         False      False   \n",
      "4                ATL        PT7H52M           False         False      False   \n",
      "\n",
      "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
      "0     103.98  ...           1653107460||1653126600   \n",
      "1     103.98  ...           1653107460||1653126600   \n",
      "2     103.98  ...           1653107460||1653126600   \n",
      "3     103.98  ...           1653107460||1653126600   \n",
      "4     103.98  ...           1653107460||1653126600   \n",
      "\n",
      "                              segmentsArrivalTimeRaw  \\\n",
      "0  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "1  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "2  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "3  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "4  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
      "\n",
      "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
      "0                   DEN||ATL                     OAK||DEN   \n",
      "1                   DEN||ATL                     OAK||DEN   \n",
      "2                   DEN||ATL                     OAK||DEN   \n",
      "3                   DEN||ATL                     OAK||DEN   \n",
      "4                   DEN||ATL                     OAK||DEN   \n",
      "\n",
      "                    segmentsAirlineName segmentsAirlineCode  \\\n",
      "0  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "1  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "2  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "3  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "4  Frontier Airlines||Frontier Airlines              F9||F9   \n",
      "\n",
      "  segmentsEquipmentDescription segmentsDurationInSeconds segmentsDistance  \\\n",
      "0                ||Airbus A320                      9180              943   \n",
      "1                ||Airbus A320                      9180              943   \n",
      "2                ||Airbus A320                      9180             1207   \n",
      "3                ||Airbus A320                      9180             1207   \n",
      "4                ||Airbus A320                     10620              943   \n",
      "\n",
      "  segmentsCabinCode  \n",
      "0             coach  \n",
      "1             coach  \n",
      "2             coach  \n",
      "3             coach  \n",
      "4             coach  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Unique values in segmentsCabinCode after split and explode:\n",
      "['coach' 'premium coach' 'first' 'business']\n",
      "Fitting the encoder.\n",
      "Unique categories in column startingAirport: ['OAK' 'DEN' 'LGA' 'LAX' 'ATL' 'CLT' 'PHL' 'DTW' 'IAD' 'JFK' 'DFW' 'BOS'\n",
      " 'EWR' 'SFO' 'ORD' 'MIA']\n",
      "Updated mappings for column startingAirport: defaultdict(<class 'int'>, {'OAK': 0, 'DEN': 1, 'LGA': 2, 'LAX': 3, 'ATL': 4, 'CLT': 5, 'PHL': 6, 'DTW': 7, 'IAD': 8, 'JFK': 9, 'DFW': 10, 'BOS': 11, 'EWR': 12, 'SFO': 13, 'ORD': 14, 'MIA': 15})\n",
      "Unique categories in column destinationAirport: ['ATL' 'BOS' 'CLT' 'DEN' 'DFW' 'DTW' 'EWR' 'IAD' 'JFK' 'LAX' 'LGA' 'MIA'\n",
      " 'ORD' 'PHL' 'SFO' 'OAK']\n",
      "Updated mappings for column destinationAirport: defaultdict(<class 'int'>, {'ATL': 0, 'BOS': 1, 'CLT': 2, 'DEN': 3, 'DFW': 4, 'DTW': 5, 'EWR': 6, 'IAD': 7, 'JFK': 8, 'LAX': 9, 'LGA': 10, 'MIA': 11, 'ORD': 12, 'PHL': 13, 'SFO': 14, 'OAK': 15})\n",
      "Unique categories in column segmentsCabinCode: ['coach' 'premium coach' 'first' 'business']\n",
      "Updated mappings for column segmentsCabinCode: defaultdict(<class 'int'>, {'coach': 0, 'premium coach': 1, 'first': 2, 'business': 3})\n",
      "Transforming the data.\n",
      "Transformed values for column startingAirport: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Transformed values for column destinationAirport: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Transformed values for column segmentsCabinCode: [0 1 2 3]\n",
      "No missing values in the processed data.\n",
      "Checking unique values for 'startingAirport' after preprocessing:\n",
      "[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]\n",
      "\n",
      "Global mappings in the CategoricalEncoder:\n",
      "{'startingAirport': defaultdict(<class 'int'>, {}), 'destinationAirport': defaultdict(<class 'int'>, {}), 'segmentsCabinCode': defaultdict(<class 'int'>, {})}\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_preprocessor import DataPreprocessor\n",
    "\n",
    "# Create an instance of the DataPreprocessor class\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Process all folders\n",
    "preprocessor.merge_and_preprocess_all_datasets()\n",
    "\n",
    "print(\"Checking unique values for 'startingAirport' after preprocessing:\")\n",
    "print(preprocessor.data['startingAirport'].unique())\n",
    "\n",
    "print(\"\\nGlobal mappings in the CategoricalEncoder:\")\n",
    "print(preprocessor.categorical_encoder.global_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   totalTravelDistance  segmentsDurationInSeconds  segmentsDistance  \\\n",
      "0             0.339797                   0.097523          0.257879   \n",
      "1             0.339797                   0.097523          0.257879   \n",
      "2             0.339797                   0.097523          0.715852   \n",
      "3             0.339797                   0.097523          0.715852   \n",
      "4             0.339797                   0.436882          0.257879   \n",
      "\n",
      "   startingAirport  destinationAirport  segmentsCabinCode  flightDate_year  \\\n",
      "0                0                   0                  0             2022   \n",
      "1                0                   0                  0             2022   \n",
      "2                0                   0                  0             2022   \n",
      "3                0                   0                  0             2022   \n",
      "4                0                   0                  0             2022   \n",
      "\n",
      "   flightDate_month  flightDate_day  flightDate_weekday  \\\n",
      "0                 5              20                   4   \n",
      "1                 5              20                   4   \n",
      "2                 5              20                   4   \n",
      "3                 5              20                   4   \n",
      "4                 5              20                   4   \n",
      "\n",
      "   flightDate_is_weekend  segmentsDepartureTimeRaw_hour  \\\n",
      "0                  False                             18   \n",
      "1                  False                             18   \n",
      "2                  False                             18   \n",
      "3                  False                             18   \n",
      "4                  False                             18   \n",
      "\n",
      "   segmentsDepartureTimeRaw_minute  totalFare  \n",
      "0                               58     103.98  \n",
      "1                               58     103.98  \n",
      "2                               58     103.98  \n",
      "3                               58     103.98  \n",
      "4                               58     103.98  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"data/processed/merged_data_processed.csv\")\n",
    "print(df1.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "unique_values = df1['destinationAirport'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 21:54:29.746071: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-10-18 21:54:29.746130: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-10-18 21:54:29.746141: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-10-18 21:54:29.746174: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-18 21:54:29.746195: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-10-18 21:56:12.355101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 462480/4992962 [=>............................] - ETA: 14:07:13 - loss: 294213.2500 - mae: 289.9425 - mse: 294213.2500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m flight_fare_model\u001b[39m.\u001b[39mcompile_model()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m flight_fare_model\u001b[39m.\u001b[39;49mtrain_model(epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m rmse, mae \u001b[39m=\u001b[39m flight_fare_model\u001b[39m.\u001b[39mevaluate(flight_fare_model\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/GitHub/Flight_Fare_Prediction/src/models/train_model.py:105\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    103\u001b[0m deep_dropout1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.2\u001b[39m)(deep_layer1)\n\u001b[1;32m    104\u001b[0m deep_layer2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(deep_dropout1)\n\u001b[0;32m--> 105\u001b[0m deep_dropout2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.2\u001b[39m)(deep_layer2)\n\u001b[1;32m    107\u001b[0m \u001b[39m# Combine wide and deep components\u001b[39;00m\n\u001b[1;32m    108\u001b[0m combined \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mconcatenate([wide_combined, deep_dropout2])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.models.train_model import WideDeepModel\n",
    "\n",
    "# Create an instance of FlightFareModel and load data\n",
    "flight_fare_model = WideDeepModel()\n",
    "\n",
    "# Compute embedding sizes\n",
    "flight_fare_model.compute_embedding_sizes()\n",
    "\n",
    "# Build and compile the model\n",
    "flight_fare_model.build_model()\n",
    "flight_fare_model.compile_model()\n",
    "\n",
    "# Train the model\n",
    "flight_fare_model.train_model(epochs=1)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse, mae = flight_fare_model.evaluate(flight_fare_model.data)\n",
    "\n",
    "print(f\"RMSE on test set: {rmse}\")\n",
    "print(f\"MAE on test set: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.train_model import WideDeepModel\n",
    "\n",
    "# Create an instance of FlightFareModel and load data\n",
    "flight_fare_model = WideDeepModel()\n",
    "\n",
    "# Compute embedding sizes\n",
    "flight_fare_model.compute_embedding_sizes()\n",
    "\n",
    "# Hyperparameter tuning\n",
    "flight_fare_model.hyperparameter_tuning(epochs=10)\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "flight_fare_model.train_model(epochs=10)  # or more epochs\n",
    "\n",
    "# Evaluate the model\n",
    "rmse, mae = flight_fare_model.evaluate(flight_fare_model.data)\n",
    "\n",
    "print(f\"RMSE on test set: {rmse}\")\n",
    "print(f\"MAE on test set: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalraj/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4992944/4992962 [============================>.] - ETA: 0s - loss: 28148.0176 - mae: 117.9983 - mse: 28148.0176"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39msaved_model/best_model.keras\u001b[39m\u001b[39m\"\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([train_other_wide, train_startingAirport, train_destinationAirport, train_segmentsCabinCode, train_deep], train_labels, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m([valid_other_wide, valid_startingAirport, valid_destinationAirport, valid_segmentsCabinCode, valid_deep], valid_labels),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stop, reduce_lr, model_checkpoint])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Save the final model to disk\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalraj/GitHub/Flight_Fare_Prediction/notebooks/main.ipynb#X30sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodels/my_final_model.keras\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1818\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1819\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[0;32m-> 1832\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1833\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1834\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1835\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1836\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1837\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1838\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1839\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1840\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1841\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1842\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1843\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1844\u001b[0m )\n\u001b[1;32m   1845\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m }\n\u001b[1;32m   1848\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2274\u001b[0m                     data_handler,\n\u001b[1;32m   2275\u001b[0m                     step,\n\u001b[1;32m   2276\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2277\u001b[0m                 )\n\u001b[1;32m   2279\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4080\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    877\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    878\u001b[0m )\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.train_model import load_merged_data, build_model\n",
    "\n",
    "# Load and preprocess data\n",
    "data = load_merged_data()\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Compute the embedding sizes for the categorical features\n",
    "embedding_sizes = {\n",
    "    'startingAirport': (data['startingAirport'].nunique() + 1, min(50, (data['startingAirport'].nunique() + 1) // 2)),\n",
    "    'destinationAirport': (data['destinationAirport'].nunique() + 1, min(50, (data['destinationAirport'].nunique() + 1) // 2)),\n",
    "    'segmentsCabinCode': (data['segmentsCabinCode'].nunique() + 1, min(50, (data['segmentsCabinCode'].nunique() + 1) // 2))\n",
    "}\n",
    "\n",
    "# Now, build the model by passing the computed embedding sizes\n",
    "model = build_model(embedding_sizes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "# Split data into wide and deep components for training and validation\n",
    "# Convert boolean columns to int\n",
    "train_data['flightDate_is_weekend'] = train_data['flightDate_is_weekend'].astype(int)\n",
    "valid_data['flightDate_is_weekend'] = valid_data['flightDate_is_weekend'].astype(int)\n",
    "test_data['flightDate_is_weekend'] = test_data['flightDate_is_weekend'].astype(int)\n",
    "\n",
    "# For the deep component\n",
    "train_deep = train_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']].values.astype('float32')\n",
    "valid_deep = valid_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']].values.astype('float32')\n",
    "\n",
    "# Categorical inputs for wide component\n",
    "train_startingAirport = train_data['startingAirport'].values.astype('float32').reshape(-1, 1)\n",
    "valid_startingAirport = valid_data['startingAirport'].values.astype('float32').reshape(-1, 1)\n",
    "\n",
    "train_destinationAirport = train_data['destinationAirport'].values.astype('float32').reshape(-1, 1)\n",
    "valid_destinationAirport = valid_data['destinationAirport'].values.astype('float32').reshape(-1, 1)\n",
    "\n",
    "train_segmentsCabinCode = train_data['segmentsCabinCode'].values.astype('float32').reshape(-1, 1)\n",
    "valid_segmentsCabinCode = valid_data['segmentsCabinCode'].values.astype('float32').reshape(-1, 1)\n",
    "\n",
    "# The other wide features (excluding the 3 categorical features)\n",
    "train_other_wide = train_data[['flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']].values.astype('float32')\n",
    "valid_other_wide = valid_data[['flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']].values.astype('float32')\n",
    "\n",
    "train_labels = train_data['totalFare'].values.astype('float32')\n",
    "valid_labels = valid_data['totalFare'].values.astype('float32')\n",
    "\n",
    "# Train the model with early stopping, reduce learning rate on plateau, and model checkpoint\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"saved_model/best_model.keras\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit([train_other_wide, train_startingAirport, train_destinationAirport, train_segmentsCabinCode, train_deep], train_labels, \n",
    "                    validation_data=([valid_other_wide, valid_startingAirport, valid_destinationAirport, valid_segmentsCabinCode, valid_deep], valid_labels),\n",
    "                    epochs=2, \n",
    "                    callbacks=[early_stop, reduce_lr, model_checkpoint])\n",
    "\n",
    "# Save the final model to disk\n",
    "model.save(\"models/my_final_model.keras\")\n",
    "\n",
    "# Model Evaluation\n",
    "test_wide = test_data[['startingAirport', 'destinationAirport', 'segmentsCabinCode', 'flightDate_year', 'flightDate_month', 'flightDate_day', 'flightDate_weekday', 'flightDate_is_weekend', 'segmentsDepartureTimeRaw_hour', 'segmentsDepartureTimeRaw_minute']]\n",
    "test_deep = test_data[['totalTravelDistance', 'segmentsDurationInSeconds', 'segmentsDistance']]\n",
    "test_labels = test_data['totalFare']\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = model.predict([test_wide, test_deep])\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "rmse.update_state(test_labels, predictions)\n",
    "mae.update_state(test_labels, predictions)\n",
    "\n",
    "print(f\"RMSE on test set: {rmse.result().numpy()}\")\n",
    "print(f\"MAE on test set: {mae.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot MAE and MSE\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.legend()\n",
    "plt.title('Mean Absolute Error Progression During Training')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mse'], label='Train MSE')\n",
    "plt.plot(history.history['val_mse'], label='Validation MSE')\n",
    "plt.legend()\n",
    "plt.title('Mean Squared Error Progression During Training')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
